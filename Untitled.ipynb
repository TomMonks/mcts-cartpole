{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monte-Carlo Tree Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting obs: [-0.48451472  0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Set up environment and import first observation\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "obs = env.reset()\n",
    "print('Starting obs:', obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Take action (push cart to right):\n",
      "\n",
      "New state: [-0.48451472  0.        ]\n",
      "Reward: -1.0\n",
      "Done: False\n",
      "Extra info: {}\n"
     ]
    }
   ],
   "source": [
    "# Take action 1 (push cart to right and get new observation)\n",
    "print ('\\nTake action (push cart to right):')\n",
    "action = 1\n",
    "new_state, reward, done, info = env.step(action)\n",
    "print('\\nNew state:', obs)\n",
    "print('Reward:', reward)\n",
    "print('Done:', done)\n",
    "print('Extra info:', info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 20]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DISCRETE_OBS_SIZE = [20] * len(env.observation_space.high)\n",
    "DISCRETE_OBS_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discrete_state(state, env):\n",
    "    discrete_state = (state - env.observation_space.low) / discrete_obs_win_size\n",
    "    return tuple(discrete_state.astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    '''\n",
    "    Tree data structure to use with MCTS\n",
    "    '''\n",
    "    def __init__(self, n_legal_actions, parent=None, state=None):\n",
    "        self.n_legal_actions = n_legal_actions\n",
    "        self.children = [None for i in range(n_legal_actions)]\n",
    "        self.visits = 0\n",
    "        self.q_value = 0.0\n",
    "    \n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        \n",
    "        #array representation of children visits\n",
    "        self.bandit_means = np.empty(n_legal_actions, np.float)\n",
    "        self.actions = np.zeros(n_legal_actions, np.int32)\n",
    "            \n",
    "    def __iter__(self):\n",
    "        self.n = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.n < self.n_legal_actions:\n",
    "            self.n += 1\n",
    "            return self.children[self.n-1]\n",
    "        else:\n",
    "            raise StopIteration\n",
    "            \n",
    "    def expand(self):\n",
    "        for idx in range(self.n_legal_actions):\n",
    "            self.children[idx] = TreeNode(self.n_legal_actions, parent=self)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "<__main__.TreeNode object at 0x7fe2ddae1c10>\n",
      "<__main__.TreeNode object at 0x7fe2ddae1f70>\n",
      "<__main__.TreeNode object at 0x7fe2ddae1df0>\n"
     ]
    }
   ],
   "source": [
    "x = TreeNode(3)\n",
    "\n",
    "for child in x:\n",
    "    print(child)\n",
    "\n",
    "x.expand()\n",
    "\n",
    "for child in x:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BanditAgent(ABC):\n",
    "    '''\n",
    "    Abstract base class for bandit agents\n",
    "    '''\n",
    "    @abstractmethod\n",
    "    def select_action(self, node):\n",
    "        pass\n",
    "    \n",
    "class EpsilonGreedy(BanditAgent):\n",
    "    '''\n",
    "    Epsilon-greedy agent for Tree Search.\n",
    "    \n",
    "    Explore epsilon of the time and exploit 1 - epsilon.\n",
    "    '''\n",
    "    def __init__(self, epsilon, random_state=None):\n",
    "        self.epsilon = epsilon\n",
    "        self._rand = np.random.RandomState(seed=random_state)\n",
    "        \n",
    "    def select_action(self, node):\n",
    "        u = self._rand.random()\n",
    "        if u > self.epsilon:\n",
    "            child_index = np.argmax(node.bandit_means)\n",
    "        else:\n",
    "            child_index = self._rand.choice(node.bandit_means)\n",
    "            \n",
    "        return node.children[child_index], action\n",
    "\n",
    "class UCB1(BanditAgent):\n",
    "    '''\n",
    "    UCB1 Agent for tree search\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select_action(self, node):\n",
    "        '''\n",
    "        Select the action to take from a tree node based on\n",
    "        UCB1 score (highest confidence bound)\n",
    "        \n",
    "        UCB1 = mean_child + 2. Sqrt(ln(N_parent)/ n_child)\n",
    "        \n",
    "        where:\n",
    "        \n",
    "            mean_child = mean Q value of child\n",
    "            \n",
    "            N_parent = no. time parent visited.\n",
    "            \n",
    "            n_child = no. times child node has been visited.\n",
    "            \n",
    "        When n_child = 0 then UCB1 = inf.  In this case UCB1 chooses the first\n",
    "        child node in the list with inf upper bound.\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        TreeNode\n",
    "            The selected child node.\n",
    "        '''\n",
    "        half_widths = (2 * np.sqrt((np.log(node.visits) / node.actions)))\n",
    "        upper_bounds = node.bandit_means + half_widths\n",
    "        action = np.argmax(upper_bounds)\n",
    "        return node.children[action], action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS(object):\n",
    "    def __init__(self, env, n_legal_actions, bandit_agent):\n",
    "        self.env = env\n",
    "        self.state = [] \n",
    "        self.root = TreeNode(n_legal_actions)\n",
    "        self.bandit_agent = bandit_agent\n",
    "        \n",
    "    def solve(self, iterations=5):\n",
    "        for i in range(iterations):\n",
    "            leaf = self.traverse_tree(self.root)\n",
    "            leaf.expand()\n",
    "            self.rollout(leaf)\n",
    "            self.backpropogate()\n",
    "            \n",
    "    def traverse_tree(self):\n",
    "        '''\n",
    "        Traverse the search tree.  Treats each tree node\n",
    "        as a bandit problem.  \n",
    "        \n",
    "        Returns:\n",
    "        ----------\n",
    "        TreeNode\n",
    "            Leaf node on the tree (i.e has not been visited)\n",
    "        '''\n",
    "        current_node = root\n",
    "        while current_node.visits > 0:\n",
    "            current_node, action = self.bandit_agent.select_action(current_node)\n",
    "            new_state, reward, done, info = self.env.step(action)\n",
    "                        \n",
    "        return current_node\n",
    "            \n",
    "    def rollout(self, node):\n",
    "        #copy states\n",
    "        visited = {}\n",
    "        states_copy = self.states[:]\n",
    "        current_state = states_copy[-1]\n",
    "        \n",
    "    def backpropogate(self):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = MCTS(env=env, n_legal_actions=3, bandit_agent=UCB1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class RLTicTacToeAdaptor(object): \n",
    "    '''\n",
    "    adapts TicTacToe so that it can be played by an agent\n",
    "    '''\n",
    "    def __init__(self, board_size=3):\n",
    "        '''\n",
    "        Constructor\n",
    "        \n",
    "        Parameters:\n",
    "        --------\n",
    "        board_size: int optional (default=3)\n",
    "            board will be board_size X board_size\n",
    "        '''\n",
    "        self.board_size = board_size\n",
    "        self.reset()\n",
    "        self.REWARD_DRAW = 0.5\n",
    "        self.REWARD_LOSE = 0.0\n",
    "        self.REWARD_WIN = 1.0\n",
    "        self.REWARD_STEP = -0.1\n",
    "    \n",
    "    def step(self, action):\n",
    "        '''\n",
    "        Returns:\n",
    "        --------\n",
    "        Tuple\n",
    "            new_state, reward, done, info\n",
    "        '''\n",
    "        coord = self.actions[action]\n",
    "        done = self.game.place_piece(coord)\n",
    "        \n",
    "        if done and self.draw:\n",
    "            reward = self.REWARD_DRAW\n",
    "        elif done:\n",
    "            reward = self.REWARD_WIN\n",
    "        else:\n",
    "            reward = self.REWARD_STEP\n",
    "          \n",
    "        return self.get_hashable_board(), reward, done, _\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        '''\n",
    "        Reset game\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "            np.array\n",
    "            initial state\n",
    "            vector len = self.board_size x self_boardsize representing board\n",
    "        '''\n",
    "        self.game = TicTacToe(board_size=self.board_size)\n",
    "        self.actions = {}\n",
    "        \n",
    "        #init action dict\n",
    "        action = 0\n",
    "        for row in range(self.board_size):\n",
    "            for col in range(self.board_size):\n",
    "                self.actions[action] = (row, col)\n",
    "                action += 1\n",
    "        \n",
    "        return self.get_hashable_board()\n",
    "        \n",
    "    \n",
    "    def get_hashable_board(self):\n",
    "        '''\n",
    "        Reshape board from matrix to vector\n",
    "        \n",
    "        Returns:\n",
    "        ------\n",
    "            np.array\n",
    "            board as vector\n",
    "        '''\n",
    "        return self.game.board.reshape(self.board_size * self.board_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe(object):\n",
    "    '''\n",
    "    Basic TicTacToe game\n",
    "    '''\n",
    "    def __init__(self, board_size=3):\n",
    "        self.rows = board_size\n",
    "        self.cols = board_size\n",
    "\n",
    "        self.NAUGHTS = 0\n",
    "        self.CROSSES = 1\n",
    "        self.EMPTY = -1\n",
    "        \n",
    "        #naughts go first.\n",
    "        self.player = self.NAUGHTS\n",
    "        self.board = np.full((self.rows, self.cols), self.EMPTY, dtype=np.int)\n",
    "        self.draw = False\n",
    "\n",
    "        \n",
    "    def place_piece(self, coord):\n",
    "        '''\n",
    "        Player places piece on board\n",
    "        \n",
    "        Parameters:\n",
    "        ------\n",
    "        coord - array-like,\n",
    "            x, y board coordinates\n",
    "        '''\n",
    "        self.board[coord[0]][coord[1]] = self.player\n",
    "        done = self.terminal_state(coord)\n",
    "        self.end_player_turn()\n",
    "        return done\n",
    "\n",
    "    def get_legal_moves(self):\n",
    "        '''\n",
    "        Return array of legal coordinates in the grid\n",
    "        '''\n",
    "        return np.transpose(np.nonzero(self.board == self.EMPTY))\n",
    "    \n",
    "    def get_plays_remaining(self):\n",
    "        '''\n",
    "        Get plays remaining (empty places on board)\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        int\n",
    "        '''\n",
    "        return len(self.get_legal_moves())\n",
    "    \n",
    "    def legal_action(self, action): \n",
    "        '''\n",
    "        Is action legal?\n",
    "        \n",
    "        Parameters:\n",
    "        ---------\n",
    "        action - int\n",
    "            action represented as index\n",
    "            \n",
    "        Returns:\n",
    "        ---------\n",
    "        bool\n",
    "            True/False action is legal\n",
    "        '''\n",
    "        if not action in self.actions:\n",
    "            return False\n",
    "        \n",
    "        coords = self.actions[action]\n",
    "        \n",
    "        if coords not in self.get_legal_moves():\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def terminal_state(self, last_play_coord):\n",
    "        '''\n",
    "        terminal state (end of game) if\n",
    "        \n",
    "        all pieces in row are the same\n",
    "        all pieces in a col are the same\n",
    "        all pieces diag left to right are equal \n",
    "        all pieces diag right to left are equal\n",
    "        there are no places left to play\n",
    "        \n",
    "        Parameters:\n",
    "        ---------\n",
    "        last_play_coord: array-like\n",
    "            coordinates of last piece played\n",
    "        \n",
    "        Returns:\n",
    "        -------\n",
    "        bool\n",
    "            True/False indicated the game has been won/drawn\n",
    "        '''\n",
    "        coord = last_play_coord\n",
    "        \n",
    "        #row of last play\n",
    "        row = self.board[coord[0],:]\n",
    "        \n",
    "        #col of last play\n",
    "        col = self.board[:,coord[1]]\n",
    "        \n",
    "        lr_diag = np.diag(self.board)\n",
    "        \n",
    "        #quick hack only works for 3 x 3 game\n",
    "        rl_diag = np.array([self.board[0][2], self.board[1][1], \n",
    "                            self.board[2][0]])\n",
    "        \n",
    "        plays_remaining = self.get_plays_remaining()\n",
    "            \n",
    "        #draw\n",
    "        if plays_remaining == 0:\n",
    "            return True\n",
    "        #row complete\n",
    "        elif (row == self.player).astype(int).sum() == self.rows:\n",
    "            return True\n",
    "        #col complete\n",
    "        elif (col == self.player).astype(int).sum() == self.cols:\n",
    "            return True\n",
    "        #left right diagonal complete\n",
    "        elif (lr_diag == self.player).astype(int).sum() == self.rows:\n",
    "            return True\n",
    "        #right to left diagonal\n",
    "        elif (rl_diag == self.player).astype(int).sum() == self.rows:\n",
    "            return True\n",
    "        else:\n",
    "            return False \n",
    "        \n",
    "    def end_player_turn(self):\n",
    "        '''\n",
    "        End players turn\n",
    "        '''\n",
    "        if self.player == self.CROSSES:\n",
    "            self.player = self.NAUGHTS\n",
    "        else:\n",
    "            self.player = self.CROSSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game = RLTicTacToeAdaptor()\n",
    "state = game.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_state, reward, done, info = game.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1, -1, -1, -1, -1, -1, -1, -1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
